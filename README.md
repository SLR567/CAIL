# 司法阅读理解

## 任务说明

裁判文书中包含了丰富的案件信息，比如时间、地点、人物关系等等，通过机器智能化地阅读理解裁判文书，可以更快速、便捷地辅助法官、律师以及普通大众获取所需信息。
本次任务覆盖多种法律文书类型，包括民事、刑事、行政，问题类型为多步推理，即对于给定问题，只通过单句文本很难得出正确回答，模型需要结合多句话通过推理得出答案。

## 数据说明

本任务数据集包括约5100个问答对，其中民事、刑事、行政各约1700个问答对，均为需要多步推理的问题类型。为了进行评测，按照9:1的划分，数据集分为了训练集和测试集。**注意** 该数据仅用于本课程的学习，请勿进行传播。

发放的文件为``train.json``和``dev.json``，为字典列表，字典包含字段为：

- ``_id``：案例的唯一标识符。
- ``context``：案例内容，抽取自裁判文书的事实描述部分。数据格式与HotpotQA数据格式一致，不过只包含一个篇章，篇章包括标题（第一句话）和切割后的句子列表。
- ``question``：针对案例提出的问题，每个案例只标注一个问题。
- ``answer``：问题的回答，包括片段、YES/NO、据答几种类型，对于拒答类，答案应该是"unknown"。
- ``supporting_facts``：回答问题的依据，是个列表，每个元素包括标题（第一句话）和句子编号（从0开始）。

同学们需根据案例描述和问题，给出答案及答案依据，最终会综合两部分的效果并作为评判依据，评价方法与HotpotQA一致。

我们提供基础的模型代码在`baseline`目录下

## 评分要求

分数由两部分组成。首先，读懂已有代码并添加适量注释。使用已有代码在训练数据上进行训练，并且完成开发集评测，这部分占60%，评分依据为模型的开发集性能和报告，报告主要包括对于模型基本原理的介绍，需要同学阅读代码进行学习。
第二部分，进行进一步的探索和尝试，我们将在下一小节介绍可能的尝试，并在报告中汇报尝试的方法以及结果，这部分占40%。同学需要提交代码和报告，在报告中对于两部分的实验都进行介绍。

## 探索和尝试

- 使用2019年的[阅读理解数据集（CJRC）](https://github.com/china-ai-law-challenge/CAIL2019/tree/master/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/data)作为辅助数据集，帮助模型提高阅读理解能力
- 使用别的预训练语言模型完成该实验，例如THUNLP提供的[司法BERT](https://github.com/thunlp/OpenCLaP)
- 对于新的模型架构进行探索，例如加入图神经网络（GNN）来加强模型的推理能力

## 参考资料

- [CAIL2020——阅读理解](https://github.com/china-ai-law-challenge/CAIL2020/tree/master/ydlj)